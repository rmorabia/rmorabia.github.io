{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "radhika&#39;s dev thoughts",
	"language": "en",
	"home_page_url": "https://rmorabia.com/",
	"feed_url": "https://rmorabia.com/feed/feed.json",
	"description": "...and the rest is rust and stardust.",
	"author": {
		"name": "Radhika Morabia",
		"url": "https://rmorabia.com/"
	},
	"items": [
		{
			"id": "https://rmorabia.com/blog/integration-testing/",
			"url": "https://rmorabia.com/blog/integration-testing/",
			"title": "The Limits of Front-End Testing",
			"content_html": "<p>I recently submitted a bugfix in a codebase I haven't touched in over 6 months. I added unit tests, manually QAed, and ...broke production pretty badly.</p>\n<p>I spent the next couple of days a bit shaken -- in trying to fix an edge case, I ended up breaking a fundamental flow in the app.</p>\n<p>How did this happen? We have all sorts of tests: unit tests on most functions and actions (using Jest), component-level tests on this page (using React Testing Library), and end-to-end tests that check if the flow is working (using Cypress). I felt safe in writing code I wasn't 100% familiar with. I wouldn't have been surprised if another edge case showed up, but no part of me was expecting to break the entire flow, given this test coverage.</p>\n<p>What was the leak?</p>\n<p>First, let me explain the bug, then talk about our tests. I wrote a modification to a function which saves user data to the server, which validates that data and sends it back to us to update the UI with. I made a bad assumption which is that I wanted the data in a specific part to reset to default if the user did a specific action. My code was correct given that assumption, but this would end up locking the user in a loop where it's impossible to ever actually update that data that I keep resetting to default. I, for some strange reason, thought that it would fail the back-end validation if it wasn't completely reset. This is not how it ended up working, of course, because the reset data was completely valid to the back-end, and would get saved as the user's changes every time.</p>\n<p>The fix to this was to limit the values that are reset to only be the values I actually needed to reset. So, instead of &quot;User did X, data that relies on X will reset to default,&quot; I'm changing it to &quot;User did X, data that relies on X is unchanged, but I'm changing X to Y. They'll never know.&quot; This is a bit convoluted, but my summary here is: I made a bad assumption about how data would be validated. This ended up resetting the the user's data every time they tried to save.</p>\n<p>So, how did this fail the tests, considering how easy this was to replicate in QA, and the app has a log of user actions to check if what the user actually did is what the app ended up understanding?</p>\n<p>Our component-level tests were testing whether or not the correct components rendered and the UI updated as epxected. The UI would update as expected, it was the saving to the server that failed.</p>\n<p>Okay, then if the saving failed, how did it pass those unit tests? Our unit tests were testing the server call of the specific function I was editing. My work passed all of these tests because the correct server call was being made and I wrote the first assumption of what the request body to that call should be, and of course, my code passed <em>my</em> tests. It was the UI after that wouldn't update!</p>\n<p>Okay, then if the UI didn't update correctly, how did it pass the end-to-end tests? The end-to-end tests test the entire flow, changing basically every option possible in one large test per flow, which is not how users use the app -- which would be changing one thing and that appropraitely showing up in the log.</p>\n<p>After the incident occurred, I thought: this must be such an easy test to add. How don't we have tests like that already? Every action the user takes, we have a log of what the user has done. So, it's a simple test, user does X, does log say that the user did X? Regardlesss of the request bodies and the state changes, does the app function as expected?</p>\n<p>It turns out, we never test that kind of interaction in the app. I actually have a few times in another project I did after this bug, but those tests took multiple seconds using RTL when the average time for RTL is a couple of milliseconds. I think it's against the nature of most apps to do this kind of testing: it would require adding a couple of dozen unit tests at the container level of a sub-application and drilling into sub-components.</p>\n<p>I'm the only one writing tests this way, which makes me think I'm writing these tests wrong. After this incident, I opened the RTL test for the container component of this page that was failing, expecting to write another one of these drilling tests, only to find all the sub components mocked and the functions tested in isolation. I think that's the correct way... and it wouldn't have caught my issue even if I did add that test, since just like the unit tests I wrote, I would've updated the request body to reset all my data just like I expected.</p>\n<p>I think the answer here is pretty simple: there should've already been integration tests. The ideal test for this scenario, and a lot of scenarios in this app that are constantly sending and receiving data to a back-end (more than any other app I've ever written) is to have robust integration tests. It would've set my alarm signals off if other tests failed, not the new ones I created. How do you do integration tests with React, though, without 30 minute test times in Cypress?</p>\n<p>The test that would've fixed this is in my mind: &quot;When I update Section H and hit Save, the request body is as follows. After a successful response, the user log (which is also gotten from the server) says X occurred as follows, and only X occured as follows.&quot; The important part here is these would have to be pre-existing tests, dozens of integration tests should've broken when I added my code, sending off alarm signals that this is having unintended consequences.</p>\n<p>However, the tooling, infrastructure, testing culture, and other overhead to make this happen is over my head. Even if I wanted to take this on as a project on the side now, I'm not even sure how to accomplish that given the render-focused tests that we write with RTL. I'm not the best at testing yet. I have had a copy of TDD by Kent Beck on my desk before this incident, and I will probably take the time to actually crack it open now after this incident.</p>\n",
			"date_published": "2024-09-01T00:00:00Z"
		}
		,
		{
			"id": "https://rmorabia.com/blog/dev-blogs/",
			"url": "https://rmorabia.com/blog/dev-blogs/",
			"title": "Developer Blogs &amp; Newsletters I Read",
			"content_html": "<p>This is a list of the current developer blogs, email newsletters, and YouTube channels I am subscribed to, along with some notes on whether or not they will be useful for you to follow.</p>\n<h2 id=\"the-pragmatic-engineer\" tabindex=\"-1\"><a href=\"https://www.pragmaticengineer.com/\">The Pragmatic Engineer</a> <a class=\"header-anchor\" href=\"https://rmorabia.com/blog/dev-blogs/\">#</a></h2>\n<p>Gergely is the best at telling software engineers everything they need to know about the state of the industry without the hype. I've been reading his work since he was just blogging, and have now been reading his newsletter for a couple of years. The emphasis really is on a pragmatic point of view: real, relevant news, analyses, and insider interviews. This is particularly mostly relevant if you work in the &quot;tech&quot; industry, not as an engineer in another industry.</p>\n<h2 id=\"bytes-dev\" tabindex=\"-1\"><a href=\"https://bytes.dev/\">Bytes.dev</a> <a class=\"header-anchor\" href=\"https://rmorabia.com/blog/dev-blogs/\">#</a></h2>\n<p>This is JavaScript-specific news that doesn't make me want to tear my hair out. A lot of the main focus is on trends, which is pretty irrelevant unless you're working for a startup and are choosing new technologies every day. However, they have a section that's called &quot;Spot the Bug&quot; which is a good reminder of obscure language rules, and their curation of external blog posts worth reading is a good enough mix of trends and non-trends to justify skimming twice a week.</p>\n<h2 id=\"tech-talks-weekly\" tabindex=\"-1\"><a href=\"https://techtalksweekly.substack.com/\">Tech Talks Weekly</a> <a class=\"header-anchor\" href=\"https://rmorabia.com/blog/dev-blogs/\">#</a></h2>\n<p>This is a recent and powerful discovery for me. I fundamentally believe that if you're hot a hobbyist professional and you want to keep learning, your options start to get slim very fast. You can read a couple of books a year, but I generally focus on more fundamentals and timeless books there. To keep up with a diverse set of ideas and technologies without getting bogged down in blog spam (popularity isn't a good curation metric!), tech talks are my new go-to. I try and watch anything that sounds interesting to me and shut it off in 10 minutes if it's not useful. This means, more often than not, watching talks outside of the world of JavaScript and front-end development.</p>\n<h2 id=\"software-clown-by-itamar-turner-trauring\" tabindex=\"-1\"><a href=\"https://codewithoutrules.com/\">Software Clown by Itamar Turner-Trauring</a> <a class=\"header-anchor\" href=\"https://rmorabia.com/blog/dev-blogs/\">#</a></h2>\n<p>The shortest, sweetest newsletter I get each week. Software Clown is an extraordinary series even though I've never touched Python in my life, and Itamar's books and blog posts are concise and actionable. I highly recommend this one to basically every professional software engineer. There's no encouragement to become a hobbyist who's into trends here.</p>\n<h2 id=\"will-larson\" tabindex=\"-1\"><a href=\"https://lethain.com/\">Will Larson</a> <a class=\"header-anchor\" href=\"https://rmorabia.com/blog/dev-blogs/\">#</a></h2>\n<p>Will is mostly a skip for me these days as his focus has shifted almost entirely towards writing for Staff+ Engineers and tech executives. However, I will still read just about anything that isn't specifically about those topics from him. He has written some of the most all-time engineering career posts ever, so digging through his archives is more recommended than subscribing at this point.</p>\n",
			"date_published": "2024-08-25T00:00:00Z"
		}
		,
		{
			"id": "https://rmorabia.com/blog/vs/",
			"url": "https://rmorabia.com/blog/vs/",
			"title": "How to Make Visual Studio Code 150% Faster in Large Projects",
			"content_html": "<p>I recently switched projects over to our large monorepo (the zip from GitHub is around 150mb, without <code>node_modules</code>). I found that not only was Webpack causing my fans to run on overdrive, Visual Studio Code would get so laggy that typing caused seconds of latency.</p>\n<p>I tried switching back to a simpler code editor, but I'm extremely reliant on Code's built-in search features in such a big project like this.</p>\n<p>So, I had to take some time to get to the bottom of this.</p>\n<p>Firstly, I checked Activity Monitor. I saw that something called <code>Code Helper (Renderer)</code> was taking 150% of my CPU.</p>\n<p>My initial assumption was to stop using Code's built-in terminal and switch over to iTerm. That didn't fix it.</p>\n<p>I looked at <a href=\"https://github.com/microsoft/vscode/issues/87509\">a lot of GitHub Issues about this issue</a> and saw repeated comments from the Code team that <code>Code Helper (Renderer)</code> is a process that comes from an extension. Disable all extensions and it will work.</p>\n<p>So... I did. It did not work. I didn't even have any themes installed.</p>\n<p>Finally, I came across <a href=\"https://stackoverflow.com/questions/54798028/how-do-i-figure-out-which-extension-or-service-is-making-a-vs-code-helper-proces\">an unanswered StackOverflow question</a> where the comments answered what I needed.</p>\n<p><strong>If you are having performance issues with Visual Studio Code, open <code>Developer: Open Process Explorer</code>.</strong></p>\n<p>I saw that something called <code>electron_node tsserver.js</code> was taking up over 100% of my CPU. What was this? I didn't use any TypeScript in my project.</p>\n<p>Further looking around led me to the fact that <strong>Visual Studio Code has extensions built-in that you never installed.</strong> I did not know this! You can find these by searching <code>@builtin</code> in your extensions.</p>\n<p>Specifically, there is an extension called <code>TypeScript and JavaScript Language Features</code> which includes a lot of functionality like closing tags. However, it automatically runs TypeScript features even if you don't have a TypeScript project. (This begs the question, why is Visual Studio Code so deeply integrated with TypeScript that it automatically assumes you're using it? Microsoft is selling us its entire ecoystem.)</p>\n<p>Once I disabled the <code>TypeScript: Disable Automatic Type Acquisition</code> feature, Visual Studio Code was instantly faster than I've ever seen it before.</p>\n<p><strong>TL;DR: To make Visual Studio Code extremely fast if you don't use TypeScript, add this line to your settings.json file:</strong></p>\n<pre class=\"language-json\" tabindex=\"0\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"typescript.disableAutomaticTypeAcquisition\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n<span class=\"token punctuation\">}</span></code></pre>\n",
			"date_published": "2020-07-15T00:00:00Z"
		}
		
	]
}
